{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "forced-battlefield",
   "metadata": {},
   "source": [
    "# Natural Language Processing Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-spiritual",
   "metadata": {},
   "source": [
    "In this notebook, you will apply what you have learned about natural language processing in a new dataset. As we could see, most of the time, when dealing with natural language, we can extract most of the features directly from text.\n",
    "Thus, it is up to us identifying what type of features are more interesting to use from the text.\n",
    "In this Project, you will work with a different dataset about fake and real news.\n",
    "Your goal is to have a classifier model that can identify when are fake or not.\n",
    "This is quite hard, so we are not expecting you to obtain great results. The main idea here is to practice some NLP techniques to process text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-embassy",
   "metadata": {},
   "source": [
    "### Fake or Real News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-price",
   "metadata": {},
   "source": [
    "You are going to work on a [Kaggle dataset](https://www.kaggle.com/datasets/jillanisofttech/fake-or-real-news) to train a model for classifying whether news are fake or real.\n",
    "In the link, you will find the description of each column in the dataset. Notice, that the dataset is balanced, *i.e.*, it has the same number of samples for each class (Fake and Real).\n",
    "The dataset provides only the *title* and *text* of each news, from that, you can think on strategies on how to represent such text.\n",
    "Some interesting questions to answer are:\n",
    "1. Is the title more important than the rest of the text?\n",
    "2. If we combine both title and text as a single feature, does it improve training results?\n",
    "3. Is there any feature we can extract from the text (such as the size of the text, for example) that improves training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "disabled-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import here your libraries.\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b062c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'datasets/fake_or_real_news.csv'\n",
    "news = pd.read_csv(data_path)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b03c688",
   "metadata": {},
   "source": [
    "From now, you may know it, but it is important to say the obvious, you shall train your model without the *label* column as it is what we want the model to learn. So, here, what matters is the *title* and *text* columns. Have a good coding day :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f7abb",
   "metadata": {},
   "source": [
    "> *Filipe: MY ATTEMPT STARTS FROM HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ee5c81",
   "metadata": {},
   "source": [
    "# As a first attempt, I will be using the Linear Support Vector Classification model(*choice was based on sklearn \"cheat sheet\" for ML models* ). The only feature I decided to use was 'text' for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a52ac",
   "metadata": {},
   "source": [
    "## 1) Selecting features and splitting the data into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a2c26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X = news['text']\n",
    "y = news['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8d42c",
   "metadata": {},
   "source": [
    "## 2) Building simple pipeline for easier future modifications or changes on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1368079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer()),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', LinearSVC()),  # train on bow vectors w/ Linear SVC\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30517d63",
   "metadata": {},
   "source": [
    "## 3) Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "527ddf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('classifier', LinearSVC())])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f15d31",
   "metadata": {},
   "source": [
    "## 4) Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f931e9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.95      0.92      0.93       987\n",
      "        REAL       0.91      0.95      0.93       914\n",
      "\n",
      "    accuracy                           0.93      1901\n",
      "   macro avg       0.93      0.93      0.93      1901\n",
      "weighted avg       0.93      0.93      0.93      1901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "print(classification_report(predictions, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
